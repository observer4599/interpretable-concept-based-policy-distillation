{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import statistics\n",
    "from torch.distributions.categorical import Categorical\n",
    "from IPython import display\n",
    "import copy\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from scipy import spatial\n",
    "import math\n",
    "import cv2\n",
    "from matplotlib import colors\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "from ipywidgets import interact\n",
    "from collections import defaultdict\n",
    "from src.env import ACTION_MAPPER\n",
    "from src.rl_utils import get_project_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py --load-version 0 --n-rollouts 10 --n-samples 200_000 --epochs 300 --reg-coef 5e-2  \\\n",
    "    --num-envs 10 --n-clf 25 --clf-type \"moe\" --mode \"nmf\" --algo \"ppo\" --env-id PongNoFrameskip-v4 --learning-rate 5e-3 --n-experts 4 \\\n",
    "        --n-concepts 2 --target-layer 3 --batch-size 512 --val-interval 10 --max-patience 5 --ccp-alpha 5e-5 --agent-version 0 \\\n",
    "            --save-start 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GLOBAL_INFO[\"args\"].clf_type == \"dt\":\n",
    "    model = sorted(GLOBAL_INFO[\"clf\"], key=lambda x: (\n",
    "        x[1], -x[0].clf.get_n_leaves()))[-1][0]\n",
    "elif GLOBAL_INFO[\"args\"].clf_type == \"none\":\n",
    "    model = GLOBAL_INFO[\"clf\"][0]\n",
    "else:\n",
    "    model = sorted(GLOBAL_INFO[\"clf\"], key=lambda x: x[1])[-1]\n",
    "    clf = model[0].clf\n",
    "model = model[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expert visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path().cwd().parent / \\\n",
    "    f\"experiment-data/experts/{GLOBAL_INFO['args'].env_id}\"\n",
    "\n",
    "if not folder.exists():\n",
    "    folder.mkdir(parents=True)\n",
    "\n",
    "n_concepts = model.reducer.n_components_\n",
    "\n",
    "weight = [clf.experts[i].weight.numpy(force=True)\n",
    "          for i in range(len(clf.experts))]\n",
    "weight = np.stack(weight, axis=0)\n",
    "weight = np.reshape(weight, (len(clf.experts), -1,\n",
    "                    n_concepts, 9, 9))\n",
    "\n",
    "nrows = weight.shape[2]\n",
    "ncols = weight.shape[1]\n",
    "\n",
    "\n",
    "for expert_id in range(weight.shape[0]):\n",
    "    fig_large, ax_large = plt.subplots(\n",
    "        nrows=nrows, ncols=ncols, layout=\"constrained\", figsize=(4 * ncols, 4.1 * nrows))\n",
    "    if nrows == 1:\n",
    "        ax_large = np.expand_dims(ax_large, 0)\n",
    "\n",
    "    max_ = np.max(weight[expert_id])\n",
    "    min_ = np.min(weight[expert_id])\n",
    "    largest = min(max_, abs(min_))\n",
    "    print(largest)\n",
    "    max_ = largest\n",
    "    min_ = -largest\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            fig, ax = plt.subplots(layout=\"constrained\", figsize=(4, 4.25))\n",
    "            weight_instace = weight[expert_id, col, row]\n",
    "            sns.heatmap(weight_instace, cbar=False, vmax=max_, vmin=min_,\n",
    "                        cmap=sns.color_palette(\"coolwarm\", as_cmap=True),\n",
    "                        ax=ax, square=True)\n",
    "            ax.axis(\"off\")\n",
    "            ax.set_title(\n",
    "                f\"{ACTION_MAPPER[GLOBAL_INFO['args'].env_id][col].capitalize()}\", fontsize=25)\n",
    "            fig.savefig(\n",
    "                folder /\n",
    "                f\"expert={expert_id}__concept={row}__action={ACTION_MAPPER[GLOBAL_INFO['args'].env_id][col]}_{col}.svg\",\n",
    "                bbox_inches='tight', pad_inches=0)\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Large plot\n",
    "\n",
    "            sns.heatmap(weight_instace, cbar=False, vmax=max_, vmin=min_,\n",
    "                        cmap=sns.color_palette(\"coolwarm\", as_cmap=True),\n",
    "                        ax=ax_large[row, col], square=True)\n",
    "\n",
    "            ax_large[row, col].set_xticks([])\n",
    "            ax_large[row, col].set_yticks([])\n",
    "            if row == 0:\n",
    "                ax_large[row, col].set_title(\n",
    "                    f\"{ACTION_MAPPER[GLOBAL_INFO['args'].env_id][col].capitalize()}\", fontsize=40)\n",
    "\n",
    "            if col == 0:\n",
    "                if \"Car\" in GLOBAL_INFO['args'].env_id:\n",
    "                    label = \"Grass\" if row == 0 else \"Road\"\n",
    "                elif \"Pong\" in GLOBAL_INFO['args'].env_id:\n",
    "                    label = \"Ball and\\nBackground\" if row == 0 else \"Ball and\\nPaddles\"\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                ax_large[row, col].set_ylabel(\n",
    "                    label, fontsize=40)\n",
    "\n",
    "    fig_large.savefig(\n",
    "        folder / f\"linear model__env_id={GLOBAL_INFO['args'].env_id}__expert={expert_id}.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Concept-based Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_im(args, fabric, envs, model, num_eps: int):\n",
    "    env_idx = 0\n",
    "    model.eval()\n",
    "    fabric.seed_everything(args.seed)\n",
    "    result = defaultdict(list)\n",
    "\n",
    "    next_obs = torch.tensor(envs.reset(seed=args.seed)[0],\n",
    "                            device=fabric.device)\n",
    "\n",
    "    for _ in trange(2_000):\n",
    "        with torch.no_grad():\n",
    "            concept, shape, _ = model.obs_to_concepts(\n",
    "                model.env_id, next_obs, model.agent, model.reducer)\n",
    "            mask = np.reshape(concept, shape)\n",
    "\n",
    "            expert = model.get_cluster(next_obs)\n",
    "            logits = model(next_obs)\n",
    "            action = torch.argmax(logits, -1)\n",
    "\n",
    "        result[\"expert\"].append(expert[env_idx].numpy(\n",
    "            force=True)[np.newaxis, ...])\n",
    "        result[\"obs\"].append(next_obs[env_idx].numpy(\n",
    "            force=True)[np.newaxis, ...])\n",
    "        result[\"mask\"].append(mask[env_idx][np.newaxis, ...])\n",
    "        result[\"logits\"].append(\n",
    "            logits[env_idx].numpy(force=True)[np.newaxis, ...])\n",
    "\n",
    "        if envs.envs[0].spec.id == \"CarRacing-v2\":\n",
    "            img = cv2.resize(envs.envs[0].render(), dsize=(96, 96))[:84, 6:90][\n",
    "                np.newaxis, ...]\n",
    "        elif envs.envs[0].spec.id == \"PongNoFrameskip-v4\":\n",
    "            img = cv2.resize(envs.envs[0].render()[34:-16], dsize=(84, 84))[\n",
    "                np.newaxis, ...]\n",
    "        elif envs.envs[0].spec.id == \"MsPacmanNoFrameskip-v4\":\n",
    "            img = cv2.resize(envs.envs[0].render()[:-39], dsize=(84, 84))[\n",
    "                np.newaxis, ...]\n",
    "        elif envs.envs[0].spec.id == \"BreakoutNoFrameskip-v4\":\n",
    "            img = cv2.resize(envs.envs[0].render()[32:, 8:-8], dsize=(84, 84))[\n",
    "                np.newaxis, ...]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        result[\"img\"].append(img)\n",
    "\n",
    "        next_obs, _, _, _, infos = envs.step(action.numpy(force=True))\n",
    "        next_obs = torch.tensor(next_obs, device=fabric.device)\n",
    "\n",
    "        result[\"action\"].append(action[env_idx].numpy(force=True)[np.newaxis])\n",
    "\n",
    "        if \"final_info\" not in infos:\n",
    "            continue\n",
    "\n",
    "        for info in infos[\"final_info\"]:\n",
    "            # Skip the envs that are not done\n",
    "            if info is None or \"episode\" not in info:\n",
    "                continue\n",
    "            result[\"return\"].append(info[\"episode\"][\"r\"])\n",
    "\n",
    "    result = {key: np.concatenate(value, axis=0)\n",
    "              for key, value in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_results = evaluate_im(\n",
    "    GLOBAL_INFO[\"args\"], GLOBAL_INFO[\"fabric\"], GLOBAL_INFO[\"envs\"], model, GLOBAL_INFO[\"args\"].num_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9937)\n",
    "chosen_expert = np.argmax(im_results[\"expert\"], 1)\n",
    "\n",
    "for ei in np.unique(chosen_expert):\n",
    "    print(sorted(np.random.choice(np.arange(len(chosen_expert))\n",
    "          [chosen_expert == ei], 10, False).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = get_project_folder(\n",
    ") / f\"experiment-data/samples/{GLOBAL_INFO['args'].env_id}\"\n",
    "if not folder.exists():\n",
    "    folder.mkdir(parents=True)\n",
    "\n",
    "img = im_results[\"img\"]\n",
    "action = np.argmax(im_results[\"logits\"], -1)\n",
    "expert = np.argmax(im_results[\"expert\"], -1)\n",
    "expert_prob = np.max(im_results[\"expert\"], -1)\n",
    "concepts = im_results[\"mask\"]\n",
    "weights = np.array([np.reshape(model.clf.experts[i].weight.numpy(\n",
    "    force=True), (model.clf.n_actions, -1, 9, 9)) for i in range(len(model.clf.experts))])\n",
    "\n",
    "colors = [\"Blues\", \"Reds\", \"Purples\", \"Greens\", \"Oranges\"]\n",
    "\n",
    "for i in range(len(img)):\n",
    "    fig, ax = plt.subplots(layout=\"constrained\", figsize=(5, 5))\n",
    "    masks = weights[expert[i]][action[i]] * concepts[i]\n",
    "    masks = np.array([cv2.resize(masks[j], dsize=(84, 84))\n",
    "                     for j in range(len(masks))])\n",
    "    masks = np.abs(masks)  # What to do with negative attribution?\n",
    "    masks = (masks - masks.min()) / (masks.max() - masks.min() + 1e-8)\n",
    "\n",
    "    plt.imshow(img[i])\n",
    "    for k in range(len(masks)):\n",
    "        plt.imshow(masks[k], alpha=masks[k], cmap=sns.color_palette(\n",
    "            colors[k], as_cmap=True), vmin=0, vmax=1)\n",
    "    ax.set_title(ACTION_MAPPER[GLOBAL_INFO[\"args\"].env_id]\n",
    "                 [action[i]].capitalize(), fontsize=25)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    fig.savefig(\n",
    "        folder / f\"fig{i}__expert={expert[i]}__prob={expert_prob[i]}__action={action[i]}.svg\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = get_project_folder(\n",
    ") / f\"experiment-data/concepts/{GLOBAL_INFO['args'].env_id}\"\n",
    "if not folder.exists():\n",
    "    folder.mkdir(parents=True)\n",
    "\n",
    "\n",
    "action = np.argmax(im_results[\"logits\"], -1)\n",
    "img = im_results[\"img\"]\n",
    "\n",
    "for i in range(len(img)):\n",
    "    for cj in range(len(im_results[\"mask\"][0])):\n",
    "        fig, ax = plt.subplots(layout=\"constrained\")\n",
    "        ax.imshow(im_results[\"img\"][i])\n",
    "        mask = cv2.resize(im_results[\"mask\"][i][cj], dsize=(84, 84))\n",
    "        mask = (mask - mask.min()) / (mask.max() - mask.min() + 1e-8)\n",
    "        ax.imshow(mask, alpha=mask,\n",
    "                  cmap=sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "                  )\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        fig.savefig(\n",
    "            folder / f\"fig{i}__concepts={cj}__action={action[i]}.svg\", bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = get_project_folder(\n",
    ") / f\"experiment-data/states/{GLOBAL_INFO['args'].env_id}\"\n",
    "if not folder.exists():\n",
    "    folder.mkdir(parents=True)\n",
    "\n",
    "\n",
    "img = im_results[\"img\"]\n",
    "\n",
    "for i in range(len(img)):\n",
    "    fig, ax = plt.subplots(layout=\"constrained\")\n",
    "    ax.imshow(img[i])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    fig.savefig(\n",
    "        folder / f\"fig{i}__action={im_results['action'][i]}.svg\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
